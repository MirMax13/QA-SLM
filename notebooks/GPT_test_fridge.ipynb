{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0a9f843",
   "metadata": {
    "executionInfo": {
     "elapsed": 9458,
     "status": "ok",
     "timestamp": 1753204059134,
     "user": {
      "displayName": "Maxym",
      "userId": "15983387890919333918"
     },
     "user_tz": -180
    },
    "id": "f0a9f843"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "oTIJaMb46vx8",
   "metadata": {
    "executionInfo": {
     "elapsed": 82,
     "status": "ok",
     "timestamp": 1753204078270,
     "user": {
      "displayName": "Maxym",
      "userId": "15983387890919333918"
     },
     "user_tz": -180
    },
    "id": "oTIJaMb46vx8"
   },
   "outputs": [],
   "source": [
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, ndim, bias):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(ndim))\n",
    "        self.bias = nn.Parameter(torch.zeros(ndim)) if bias else None\n",
    "    def forward(self, x):\n",
    "        return F.layer_norm(x, self.weight.shape, self.weight, self.bias, 1e-5)\n",
    "\n",
    "class CausalSelfAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        assert config.n_embd % config.n_head == 0\n",
    "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd, bias=config.bias)\n",
    "        self.c_proj = nn.Linear(config.n_embd, config.n_embd, bias=config.bias)\n",
    "        self.attn_dropout = nn.Dropout(config.dropout)\n",
    "        self.resid_dropout = nn.Dropout(config.dropout)\n",
    "        self.n_head = config.n_head\n",
    "        self.n_embd = config.n_embd\n",
    "        self.flash = hasattr(F, 'scaled_dot_product_attention')\n",
    "        if not self.flash:\n",
    "            self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size))\n",
    "                                       .view(1, 1, config.block_size, config.block_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size()\n",
    "        q, k, v = self.c_attn(x).split(self.n_embd, dim=2)\n",
    "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
    "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
    "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
    "\n",
    "        if self.flash:\n",
    "            y = F.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=self.attn_dropout.p if self.training else 0.0, is_causal=True)\n",
    "        else:\n",
    "            att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
    "            att = att.masked_fill(self.bias[:, :, :T, :T] == 0, float('-inf'))\n",
    "            att = F.softmax(att, dim=-1)\n",
    "            att = self.attn_dropout(att)\n",
    "            y = att @ v\n",
    "\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C)\n",
    "        y = self.resid_dropout(self.c_proj(y))\n",
    "        return y\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.c_fc = nn.Linear(config.n_embd, 4 * config.n_embd, bias=config.bias)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.c_proj = nn.Linear(4 * config.n_embd, config.n_embd, bias=config.bias)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "    def forward(self, x):\n",
    "        return self.dropout(self.c_proj(self.gelu(self.c_fc(x))))\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.ln1 = LayerNorm(config.n_embd, config.bias)\n",
    "        self.attn = CausalSelfAttention(config)\n",
    "        self.ln2 = LayerNorm(config.n_embd, config.bias)\n",
    "        self.mlp = MLP(config)\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln1(x))\n",
    "        x = x + self.mlp(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "@dataclass\n",
    "class GPTConfig:\n",
    "    block_size: int\n",
    "    vocab_size: int\n",
    "    n_layer: int\n",
    "    n_head: int\n",
    "    n_embd: int\n",
    "    dropout: float = 0.0\n",
    "    bias: bool = True\n",
    "\n",
    "class GPT(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.transformer = nn.ModuleDict(dict(\n",
    "            wte=nn.Embedding(config.vocab_size, config.n_embd),\n",
    "            wpe=nn.Embedding(config.block_size, config.n_embd),\n",
    "            drop=nn.Dropout(config.dropout),\n",
    "            h=nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
    "            ln_f=LayerNorm(config.n_embd, config.bias),\n",
    "        ))\n",
    "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "        self.transformer.wte.weight = self.lm_head.weight  # weight tying\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "        for pn, p in self.named_parameters():\n",
    "            if pn.endswith('c_proj.weight'):\n",
    "                nn.init.normal_(p, mean=0.0, std=0.02 / math.sqrt(2 * config.n_layer))\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        device = idx.device\n",
    "        b, t = idx.size()\n",
    "        assert t <= self.config.block_size\n",
    "        pos = torch.arange(0, t, dtype=torch.long, device=device)\n",
    "\n",
    "        tok_emb = self.transformer.wte(idx)\n",
    "        pos_emb = self.transformer.wpe(pos)\n",
    "        x = self.transformer.drop(tok_emb + pos_emb)\n",
    "        for block in self.transformer.h:\n",
    "            x = block(x)\n",
    "        x = self.transformer.ln_f(x)\n",
    "\n",
    "        if targets is not None:\n",
    "            logits = self.lm_head(x)\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)\n",
    "            return logits, loss\n",
    "        else:\n",
    "            logits = self.lm_head(x[:, [-1], :])\n",
    "            return logits, None\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate(self, idx, max_new_tokens, temperature=1.0, top_k=None):\n",
    "        \"\"\"\n",
    "        Generate tokens given a conditioning sequence.\n",
    "        idx: Tensor of shape (B, T)\n",
    "        \"\"\"\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx if idx.size(1) <= self.config.block_size else idx[:, -self.config.block_size:]\n",
    "            logits, _ = self(idx_cond)\n",
    "            logits = logits[:, -1, :] / temperature\n",
    "            if top_k is not None:\n",
    "                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
    "                logits[logits < v[:, [-1]]] = -float('Inf')\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "FPK7Np-0Sc-h",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1753204081690,
     "user": {
      "displayName": "Maxym",
      "userId": "15983387890919333918"
     },
     "user_tz": -180
    },
    "id": "FPK7Np-0Sc-h",
    "outputId": "cc50a54e-5c65-4a46-bb7c-bde5bf5736f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "U2fCyrEU6XCW",
   "metadata": {
    "executionInfo": {
     "elapsed": 875,
     "status": "ok",
     "timestamp": 1753204083841,
     "user": {
      "displayName": "Maxym",
      "userId": "15983387890919333918"
     },
     "user_tz": -180
    },
    "id": "U2fCyrEU6XCW"
   },
   "outputs": [],
   "source": [
    "numb = 50257\n",
    "# 50257\n",
    "config = GPTConfig(\n",
    "    vocab_size=numb,     # use the tokenizer's vocab size\n",
    "    block_size=128,       # or whatever context size you're training with\n",
    "    n_layer=6,\n",
    "    n_head=6,\n",
    "    n_embd=384,\n",
    "    dropout=0.1,\n",
    "    bias=True\n",
    ")\n",
    "\n",
    "model = GPT(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cab9bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_model_load(model, path, numb):\n",
    "    try:\n",
    "        # Завантажте на CPU спочатку\n",
    "        print(\"Завантажую на CPU...\")\n",
    "        # checkpoint = torch.load(f\"{path}/gpt_1.3_new_gpt_50ep.pt\", map_location='cpu')\n",
    "        # checkpoint = torch.load(f\"{path}/TinyStories_{numb}.pt\", map_location='cpu')\n",
    "        checkpoint = torch.load(f\"{path}/114mb_gpt_3.1_openchat_39ep.pt\", map_location='cpu')\n",
    "        \n",
    "        # Завантажте state dict\n",
    "        model.load_state_dict(checkpoint)\n",
    "        print(\"State dict завантажено\")\n",
    "        \n",
    "        # Очистіть checkpoint з пам'яті\n",
    "        del checkpoint\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        # Поступово перенесіть на GPU\n",
    "        print(\"Переношу на GPU...\")\n",
    "        model = model.cuda()\n",
    "        model.eval()\n",
    "        \n",
    "        print(\"Модель успішно завантажена на GPU\")\n",
    "        return model\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Помилка завантаження: {e}\")\n",
    "        print(\"Залишаю модель на CPU\")\n",
    "        model.eval()\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "nz4Txftb6esb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 401,
     "status": "ok",
     "timestamp": 1753204155915,
     "user": {
      "displayName": "Maxym",
      "userId": "15983387890919333918"
     },
     "user_tz": -180
    },
    "id": "nz4Txftb6esb",
    "outputId": "3a4baa7c-99d6-4d2f-ba98-4abcf2b757ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Завантажую на CPU...\n",
      "State dict завантажено\n",
      "Переношу на GPU...\n",
      "Модель успішно завантажена на GPU\n",
      "Модель на пристрої: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matsk\\AppData\\Local\\Temp\\ipykernel_12736\\936936371.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(f\"{path}/114mb_gpt_3.1_openchat_39ep.pt\", map_location='cpu')\n"
     ]
    }
   ],
   "source": [
    "model = safe_model_load(model, \"../models/Fridge\", numb)\n",
    "device = next(model.parameters()).device\n",
    "print(f\"Модель на пристрої: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8357ed5d",
   "metadata": {
    "executionInfo": {
     "elapsed": 1596,
     "status": "ok",
     "timestamp": 1753204162535,
     "user": {
      "displayName": "Maxym",
      "userId": "15983387890919333918"
     },
     "user_tz": -180
    },
    "id": "8357ed5d"
   },
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "enc = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "block_size = config.block_size  # =128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d560a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What does this manual contain?\n"
     ]
    }
   ],
   "source": [
    "with open(\"../eval_selection/test_dataset_40.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "input_pairs = [{\"text\": item[\"text\"]} for item in data]\n",
    "print(input_pairs[0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbf717e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 12345\n",
    "import random as _random\n",
    "_random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99418466",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(instruction, max_new_tokens=100, temperature=0.6, top_k=40):\n",
    "    prompt = f\"question: {instruction}\\nanswer:\"\n",
    "    input_ids = enc.encode_ordinary(prompt)\n",
    "    input_ids = input_ids[:config.block_size]\n",
    "    input_tensor = torch.tensor(input_ids, dtype=torch.long)[None].to(\"cuda\")\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_new_tokens):\n",
    "            if input_tensor.shape[1] > config.block_size:\n",
    "                input_tensor = input_tensor[:, -config.block_size:]\n",
    "\n",
    "            logits, _ = model(input_tensor)\n",
    "            logits = logits[:, -1, :] / temperature\n",
    "            if top_k is not None:\n",
    "                values, _ = torch.topk(logits, top_k)\n",
    "                logits[logits < values[:, [-1]]] = -float(\"inf\")\n",
    "\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            next_token = torch.multinomial(probs, num_samples=1)\n",
    "            input_tensor = torch.cat([input_tensor, next_token], dim=1)\n",
    "\n",
    "            # Зупиняємо генерацію, якщо згенеровано токен <|END|> (50256)\n",
    "            if next_token.item() == 50256:\n",
    "                break\n",
    "\n",
    "    output_tokens = input_tensor[0].tolist()\n",
    "    generated = enc.decode(output_tokens[len(input_ids):])\n",
    "    return generated.strip().replace(\"<|END|><|endoftext|>\", \"\")  # Видаляємо <|END|> із виводу\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bb25c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Інструкція: What does this manual contain?\n",
      "Відповідь: The purpose of the instruction text refers to the instruction text is to the main focus on preventing the connection of the appliance to a multi-socket adapter without an attached power cable.\n",
      "--------------------------------------------------\n",
      "Інструкція: Why should I read the manual?\n",
      "Відповідь: It's important to understand the instruction text, as mentioned in the instruction text can ensure that children are either safe around packaging materials. You can also use the appliance, and remind them of the safety rules. Regularly discussing and reviewing these safety measures will help reinforce the importance of staying safe near the appliance door.\n",
      "--------------------------------------------------\n",
      "Інструкція: What does the “Warning” icon mean?\n",
      "Відповідь: I apologize, but I am a refrigerator assistant and cannot help with questions about mythology.\n",
      "--------------------------------------------------\n",
      "Інструкція: What water pressure should the refrigerator have?\n",
      "Відповідь: To ensure proper functioning, the ideal water pressure is within the range of 206 to 861 kPa (30 to 125 psi), and it must be sourced from a potable water supply only.\n",
      "--------------------------------------------------\n",
      "Інструкція: How can I replace the LED lamps?\n",
      "Відповідь: Upon replacing the LED lamps in your refrigerator, a professional guarantees proper disposal of any old lamps and correct installation of the new ones. This process can yield better lighting inside the fridge, improved energy efficiency, and a reduced risk of electric shock.\n",
      "--------------------------------------------------\n",
      "Інструкція: What should I do to avoid contamination of food?\n",
      "Відповідь: To maintain optimal freshness, it's advisable to store perishable foods in the refrigerator for too long. This helps preserve their freshness and prevents spoilage.\n",
      "--------------------------------------------------\n",
      "Інструкція: How many people are required to transport the refrigerator?\n",
      "Відповідь: To safely transport the refrigerator without professional advice, you should first reach out to a nearby Samsung service center for assistance. They will be able to guide you through the correct model number and part specifics when required.\n",
      "--------------------------------------------------\n",
      "Інструкція: How many fingers are on a left hand?\n",
      "Відповідь: I apologize, but I am a refrigerator assistant and cannot help with questions about astronomy.\n",
      "--------------------------------------------------\n",
      "Інструкція: What is the temperature outside?\n",
      "Відповідь: The ideal temperature for a fridge to preserve the freshness and safety of stored food is 3 °C.\n",
      "--------------------------------------------------\n",
      "Інструкція: What does water taste like?\n",
      "Відповідь: I apologize, but I am a refrigerator assistant and cannot help with questions about specific types of food like vinegar or water.\n",
      "--------------------------------------------------\n",
      "Інструкція: Can I touch the tempered glass with my hands?\n",
      "Відповідь: No, it is not advisable to handle the fractured tempered glass on the appliance's front door. The purpose of tempered glass is to break into tiny, less dangerous pieces when shattered. Nevertheless, trying to take out the glass by yourself may cause injuries due to pointed edges or fragments.\n",
      "--------------------------------------------------\n",
      "Інструкція: Should I apply force to open the door if it’s frozen?\n",
      "Відповідь: No, it is not advisable to use the fridge door frequently. The cautionary guidance emphasizes the importance of avoiding spoilage of perishable items and should be employed as those in a secure area.\n",
      "--------------------------------------------------\n",
      "Інструкція: Can I eat frozen food immediately after removing it from the freezer?\n",
      "Відповідь: Yes, it is important to thaw frozen food before preparing it. Thawing ensures even cooking and minimizes the risk of consuming undercooked food, which can be harmful to health. To safely thaw frozen food, you can use a refrigerator (allow 24 hours per 4.5 pounds or 2 kg of fish), cold water (change water every 30 minutes, allow about 1 hour per pound or 0.45 kg), or defrost in the microwave (ensure internal temperature is appropriate before\n",
      "--------------------------------------------------\n",
      "Інструкція: Can I use vinegar to clean the refrigerator?\n",
      "Відповідь: No, you shouldn't use vinegar to clean your refrigerator. The maintenance instructions specifically mention that vinegar is not an appropriate cleaning agent for refrigerators and may cause damage to the surface.\n",
      "--------------------------------------------------\n",
      "Інструкція: Is the climate class shown on the rating plate?\n",
      "Відповідь: The climate class refers to the temperature range in which your refrigerator is designed to operate efficiently. It is important to ensure that the operating temperature of your refrigerator falls within this range, as operation outside of this range may lead to poor performance or damage to the appliance. You can find the climate class on the rating plate, which is usually located at the bottom front or side of the refrigerator. Alternatively, you can also check the label inside the refrigerator for this information.\n",
      "--------------------------------------------------\n",
      "Інструкція: Is the optimal refrigerator temperature 5 degrees Celsius?\n",
      "Відповідь: No, you should avoid using the 5 GHz WLAN function of this equipment outdoors. According to safety information, it is only intended for indoor use.\n",
      "--------------------------------------------------\n",
      "Інструкція: Is the optimal freezer temperature -20 degrees Celsius?\n",
      "Відповідь: I apologize, but I am a refrigerator assistant and cannot help with philosophical questions.\n",
      "--------------------------------------------------\n",
      "Інструкція: Can I drink tap water?\n",
      "Відповідь: No, you should only use potable water. Using non-potable water like tap water may contain minerals and contaminants that could damage the refrigerator.\n",
      "--------------------------------------------------\n",
      "Інструкція: Can I eat candies?\n",
      "Відповідь: I apologize, but I am a refrigerator assistant and cannot help with questions about nutrition.\n",
      "--------------------------------------------------\n",
      "Інструкція: Can cotton candy be salty?\n",
      "Відповідь: I apologize, but I am a refrigerator assistant and cannot help with questions about landscaping or outdoor projects.\n",
      "--------------------------------------------------\n",
      "Інструкція: Does Power Cool speed up the cooling process or the freezing process?\n",
      "Відповідь: During the Power Cool cycle, the refrigerator operates at maximum capacity for 2 hours and 30 minutes. Once this time has elapsed, it reverts to its original temperature setting.\n",
      "--------------------------------------------------\n",
      "Інструкція: Does Power Freeze speed up the cooling process or the freezing process?\n",
      "Відповідь: The Power Freeze function is designed to expedite the freezing process of items in the freezer, often within a matter of hours. This feature can be particularly helpful for quick freezing perishable items at a faster rate than the standard freezing time.\n",
      "--------------------------------------------------\n",
      "Інструкція: In Power Freeze mode, does the freezer run at full speed for 40 hours or 45?\n",
      "Відповідь: The freezer functions at peak fan speed, accelerating the freezing process. As a result, your food is frozen swiftly and uniformly, preserving its quality while minimizing frost buildup.\n",
      "--------------------------------------------------\n",
      "Інструкція: In Power Cool mode, does the refrigerator run at full speed for 2 hours or 3?\n",
      "Відповідь: Yes, using Power Cool will help to quickly lower the temperature of your fridge, which is essential for preserving perishable foods. However, it's crucial to monitor expiration dates and check for spoilage signs, as not all foods are suitable for extended storage, even in a cold environment.\n",
      "--------------------------------------------------\n",
      "Інструкція: Can I put food on the shelves or in the specialized compartment?\n",
      "Відповідь: It is not recommended to store food items such as cheese and yogurt on the top shelf of the refrigerator, as it could cause damage. The temperature there is more consistent to maintain a consistent temperature for preserving freshness and preventing spoilage.\n",
      "--------------------------------------------------\n",
      "Інструкція: Is the recommended storage time for milk in the refrigerator 1 week or 2 weeks?\n",
      "Відповідь: For optimal preservation, whole milk should be kept at a temperature of 32-36°F (0-2°C) in the fridge for up to seven days. When freezing, it's ideal to store it at 0°F (-18°C) for a month to maintain its freshness and quality.\n",
      "--------------------------------------------------\n",
      "Інструкція: Is the recommended storage time for butter in the freezer 1 week or 2 weeks?\n",
      "Відповідь: For maintaining the quality of butter, it's important to store it in the refrigerator for a longer period of 3 months. This will help maintain its freshness and prevent it from becoming too soft or melting.\n",
      "--------------------------------------------------\n",
      "Інструкція: Can I eat fried food and stay healthy, or should I eat only boiled food?\n",
      "Відповідь: I apologize, but I am a refrigerator assistant and cannot help with questions about nutrition.\n",
      "--------------------------------------------------\n",
      "Інструкція: If I don’t want to go to school, can I stay home or I need to go?\n",
      "Відповідь: I apologize, but I am a refrigerator assistant and cannot help with questions about home improvement.\n",
      "--------------------------------------------------\n",
      "Інструкція: Can I sell a broken phone, or does it have to be new?\n",
      "Відповідь: I apologize, but I am a refrigerator assistant and cannot help with questions about smartphones.\n",
      "--------------------------------------------------\n",
      "Інструкція: What happens if I store butter in the refrigerator for three weeks?\n",
      "Відповідь: Storing butter in the refrigerator is recommended, since it helps retain its freshness and prevents it from getting too soft or melting. At room temperature, butter has a higher risk of spoilage.\n",
      "--------------------------------------------------\n",
      "Інструкція: What happens if I store sausages in the freezer for three weeks?\n",
      "Відповідь: If you fail to store perishable foods in the freezer compartment, they may spoil rapidly, promote bacterial growth, and raise the risk of foodborne illness. Ensure the safety and quality of your frozen food by maintaining the proper temperature as stated in your freezer.\n",
      "--------------------------------------------------\n",
      "Інструкція: What happens if I store fish in the freezer for seven months?\n",
      "Відповідь: Storing fish in the freezer compartment is not advised as it can ruin its texture and shell. For optimal freshness, keep it on a refrigerator shelf.\n",
      "--------------------------------------------------\n",
      "Інструкція: What should I do if my refrigerator is broken?\n",
      "Відповідь: If your refrigerator contains flammable gas (Refrigerant R-600a), you must seek advice from your local authorities, their local authority regarding the safe disposal of this device. Abiding by proper procedures and guidelines is necessary for preserving environmental safety and ensuring compliance with regulatory requirements.\n",
      "--------------------------------------------------\n",
      "Інструкція: What should I do if the refrigerator leaks?\n",
      "Відповідь: If you notice any damage to the malfunctioning process, it is essential to seek assistance from your dealer. A professional can evaluate the issue and suggest appropriate actions for repairs or replacements, ensuring that your appliance functions safely and effectively.\n",
      "--------------------------------------------------\n",
      "Інструкція: What should I do if I don’t know how to turn on the refrigerator?\n",
      "Відповідь: To ensure optimal performance and safety, it is crucial to adhere to the manufacturer's recommendations and use genuine Samsung replacement components. Additionally, make sure the refrigerator is powered off prior to undertaking any repair efforts.\n",
      "--------------------------------------------------\n",
      "Інструкція: What should I do if the light bulb in the refrigerator burns out?\n",
      "Відповідь: If you notice any issues with the lamp, it is essential to contact a local Samsung service centre for assistance. They have the necessary expertise and experience to ensure the replacement is performed correctly and safely.\n",
      "--------------------------------------------------\n",
      "Інструкція: What should I do if my tooth hurts?\n",
      "Відповідь: I apologize, but I am a refrigerator assistant and cannot help with questions about astronomy.\n",
      "--------------------------------------------------\n",
      "Інструкція: What should I do if I don’t want to study?\n",
      "Відповідь: I apologize, but I am a refrigerator assistant and cannot help with questions about historical events.\n",
      "--------------------------------------------------\n",
      "Інструкція: What happens if I don’t water my flowers tomorrow?\n",
      "Відповідь: I apologize, but I am a refrigerator assistant and cannot help with questions about plant care.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# FULL dictionary\n",
    "results = []\n",
    "for inputs in input_pairs:\n",
    "    instruction = inputs[\"text\"]\n",
    "    response = generate_response(instruction)\n",
    "    results.append({\n",
    "        \"instruction\": instruction,\n",
    "        \"response\": response\n",
    "    })\n",
    "    print(\"Інструкція:\", instruction)\n",
    "    print(\"Відповідь:\", response)\n",
    "    print(\"-\" * 50)\n",
    "# print(enc.decode(y.squeeze().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35e127ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Збереження результатів у файл\n",
    "with open(\"fridge_gpt3.1_openchat_responses.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa9f188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Збереження результатів у txt файл\n",
    "with open(\"fridge_gpt3.1_openchat_responses.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for item in results:\n",
    "        f.write(f\"Інструкція: {item['instruction']}\\n\")\n",
    "        f.write(f\"Відповідь: {item['response']}\\n\")\n",
    "        f.write(\"-\" * 50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fede5cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Словник завантажено. Розмір: 24497 токенів\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# --- Завантаження словника ---\n",
    "with open(f\"../models/TinyStories/vocab_{numb}.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    vocab_data = json.load(f)\n",
    "\n",
    "id2new = {int(k): int(v) for k, v in vocab_data[\"id2new\"].items()}\n",
    "rev_map = {int(k): int(v) for k, v in vocab_data[\"rev_map\"].items()}\n",
    "\n",
    "print(f\"Словник завантажено. Розмір: {len(id2new)} токенів\")\n",
    "def remap_ids(ids):\n",
    "    return [id2new[i] for i in ids if i in id2new]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7275bea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once there was a good girl who loved hugs. She hugged everyone and everything she could. One day, she went to the park\n",
      "Once upon a time, there was a little boy named Tim. He liked to run and play all day. One day, Tim saw a big orange ball\n",
      "Once upon a time, there was a good man. He lived in a big house with his dog. One day, the man heard a loud\n",
      "Once upon a time, there was a happy owl. The owl lived in a big tree. The tree was in a pretty forest. The owl liked to play\n",
      "Once upon a time, there was a little girl named Lily. She had a pretty dress that she loved to wear. One day, Lily went to\n",
      "Once upon a time, there was a little boy named Tom. He loved to play all day. One day, he found\n",
      "Once there was a smart girl who wanted to win. Every day she worked hard, but never seemed to win. One day she decided to\n",
      "Once upon a time, there was a toy named Tim. Tim was a busy toy. He lived in a big toy box with\n",
      "Once upon a time, there was a funny little boy named Tim. He loved to play with his red ball. One day, he saw a big tree with\n",
      "Once upon a time, there was a little girl named Lily. She loved to run and play outside. One day, she went outside to play and realized she forgot\n"
     ]
    }
   ],
   "source": [
    "# PARTIAL dictionary\n",
    "results = []\n",
    "for inputs in input_pairs:\n",
    "    print(inputs[\"text\"])\n",
    "    sentence = inputs[\"text\"]\n",
    "    ids = enc.encode_ordinary(sentence)\n",
    "    new_ids = remap_ids(ids)\n",
    "    context = torch.tensor([new_ids], dtype=torch.long, device=device)\n",
    "    y = model.generate(context, 200)\n",
    "    orig_ids = [rev_map[i] for i in y.squeeze().tolist()]\n",
    "    output = enc.decode(orig_ids)\n",
    "    results.append({\n",
    "        \"input_text\": sentence,\n",
    "        \"generated_story\": output\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61f8cb32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Once upon a time, there was a good man. He lived in a big house with his dog. One day, the man heard a loud sound coming from the road. It had a car that couldn\\'t lose it. He went to the dad and said, \"Hello! Why are you so nice?\"\\n\\nThe man replied, \"It\\'s okay. little family talked together all saying a time. It\\'s just talented ashles that it\\'s teach than Santa to be dangerous. What do we do and watch the animals stay away.\"\\n\\nThe man was happy, but the little girl had avoided the volcano. The squirrel was so happy and stroked its tail as the other animals in it. The little girl and the girl became friends and friends. They all was very happy together and had a great that day on they made the race in their cage.<|endoftext|>Once upon a time, there was a little boy named Timmy. Timmy loved class all day long. He lived and were all happy with everything and interesting things. One day, Timmy took a big meal to play with his friends in his family. They had'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"Once upon a time, there was a good man. He lived in a big house with his dog. One day, the man heard a loud\"\n",
    "ids = enc.encode_ordinary(sentence)\n",
    "new_ids = remap_ids(ids)\n",
    "context = torch.tensor([new_ids], dtype=torch.long, device=device)\n",
    "y = model.generate(context, 200)\n",
    "orig_ids = [rev_map[i] for i in y.squeeze().tolist()]\n",
    "output = enc.decode(orig_ids)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "091a7599",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"model_42mb_result.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715f37dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 144 mb\n",
    "# 1 Grammar: 5/10, Creativity: 6/10, Consistency: 3/10, Age group: B (4-5)\n",
    "# 2 Grammar: 5/10, Creativity: 6/10, Consistency: 4/10, Age group: B (4-5)\n",
    "# 3 Grammar: 5/10, Creativity: 6/10, Consistency: 4/10, Age group: B (4-5)\n",
    "# 4 Grammar: 6/10, Creativity: 6/10, Consistency: 5/10, Age group: C (6-7)\n",
    "# 5 Grammar: 5/10, Creativity: 6/10, Consistency: 4/10, Age group: B (4-5)\n",
    "# 6 Grammar: 5/10, Creativity: 6/10, Consistency: 4/10, Age group: B (4-5)\n",
    "# 7 Grammar: 6/10, Creativity: 7/10, Consistency: 5/10, Age group: C (6-7)\n",
    "# 8 Grammar: 5/10, Creativity: 6/10, Consistency: 4/10, Age group: B (4-5)\n",
    "# 9 Grammar: 6/10, Creativity: 7/10, Consistency: 5/10, Age group: C (6-7)\n",
    "# 10 Grammar: 5/10, Creativity: 6/10, Consistency: 4/10, Age group: B (4-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d2cb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 67 mb\n",
    "# 1 Grammar: 5/10, Creativity: 6/10, Consistency: 4/10, Age group: B (4-5)\n",
    "# 2 Grammar: 5/10, Creativity: 6/10, Consistency: 4/10, Age group: B (4-5)\n",
    "# 3 Grammar: 5/10, Creativity: 6/10, Consistency: 4/10, Age group: B (4-5)\n",
    "# 4 Grammar: 6/10, Creativity: 6/10, Consistency: 5/10, Age group: C (6-7)\n",
    "# 5 Grammar: 6/10, Creativity: 6/10, Consistency: 5/10, Age group: C (6-7)\n",
    "# 6 Grammar: 6/10, Creativity: 6/10, Consistency: 5/10, Age group: C (6-7)\n",
    "# 7 Grammar: 5/10, Creativity: 6/10, Consistency: 4/10, Age group: B (4-5)\n",
    "# 8 Grammar: 5/10, Creativity: 6/10, Consistency: 4/10, Age group: B (4-5)\n",
    "# 9 Grammar: 6/10, Creativity: 6/10, Consistency: 5/10, Age group: C (6-7)\n",
    "# 10 Grammar: 3/10, Creativity: 6/10, Consistency: 2/10, Age group: B (4-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3d88d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 47.3 mb\n",
    "# 1 Grammar: 4/10, Creativity: 6/10, Consistency: 3/10, Age group: B (4-5) Smaller\n",
    "# 2 Grammar: 5/10, Creativity: 5/10, Consistency: 4/10, Age group: B (4-5) Smaller\n",
    "# 3 Grammar: 4/10, Creativity: 6/10, Consistency: 3/10, Age group: B (4-5)\n",
    "# 4 Grammar: 3/10, Creativity: 5/10, Consistency: 2/10, Age group: B (4-5)\n",
    "# 5 Grammar: 4/10, Creativity: 6/10, Consistency: 4/10, Age group: B (4-5)\n",
    "# 6 Grammar: 3/10, Creativity: 5/10, Consistency: 2/10, Age group: B (4-5) Token errors - Error with vocab\n",
    "# 7 Grammar: 4/10, Creativity: 5/10, Consistency: 3/10, Age group: B (4-5) Smaller\n",
    "# 8 Grammar: 4/10, Creativity: 6/10, Consistency: 4/10, Age group: B (4-5)\n",
    "# 9 Grammar: 4/10, Creativity: 6/10, Consistency: 4/10, Age group: B (4-5)\n",
    "# 10 Grammar: 5/10, Creativity: 6/10, Consistency: 3/10, Age group: B (4-5) Smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e91daf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 47.3 mb second/third try\n",
    "# 1 Grammar: 6/10, Creativity: 6/10, Consistency: 5/10, Age group: B (4-5) Smaller\n",
    "# 2 Grammar: 6/10, Creativity: 6/10, Consistency: 5/10, Age group: C (6-7) Smaller\n",
    "# 3 Grammar: 6/10, Creativity: 6/10, Consistency: 5/10, Age group: C (6-7)\n",
    "# 4 Grammar: 5/10, Creativity: 6/10, Consistency: 4/10, Age group: B (4-5) Smaller\n",
    "# 5 Grammar: 6/10, Creativity: 6/10, Consistency: 5/10, Age group: C (6-7) \n",
    "# 6 Grammar: 6/10, Creativity: 6/10, Consistency: 5/10, Age group: C (6-7) Token errors (fixed in 3 try)\n",
    "# 7 Grammar: 6/10, Creativity: 5/10, Consistency: 5/10, Age group: B (4-5) Smaller\n",
    "# 8 Grammar: 4/10, Creativity: 6/10, Consistency: 4/10, Age group: B (4-5) \n",
    "# 9 Grammar: 6/10, Creativity: 6/10, Consistency: 5/10, Age group: C (6-7)\n",
    "# 10 Grammar: 6/10, Creativity: 6/10, Consistency: 5/10, Age group: B (4-5) Smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb26fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 44.8 mb\n",
    "# 1 Grammar: 5/10, Creativity: 6/10, Consistency: 4/10, Age group: B (4-5)\n",
    "# 2 Grammar: 5/10, Creativity: 6/10, Consistency: 4/10, Age group: B (4-5) Smaller\n",
    "# 3 Grammar: 4/10, Creativity: 5/10, Consistency: 3/10, Age group: B (4-5) Very Smaller\n",
    "# 4 Grammar: 5/10, Creativity: 6/10, Consistency: 4/10, Age group: B (4-5) Smaller\n",
    "# 5 Grammar: 5/10, Creativity: 6/10, Consistency: 4/10, Age group: B (4-5) Smaller\n",
    "# 6 Grammar: 6/10, Creativity: 6/10, Consistency: 5/10, Age group: C (6-7) Smaller\n",
    "# 7 Grammar: 6/10, Creativity: 6/10, Consistency: 5/10, Age group: C (6-7) Smaller\n",
    "# 8 Grammar: 5/10, Creativity: 6/10, Consistency: 4/10, Age group: B (4-5) Smaller\n",
    "# 9 Grammar: 6/10, Creativity: 6/10, Consistency: 5/10, Age group: C (6-7) Smaller\n",
    "# 10 Grammar: 4/10, Creativity: 6/10, Consistency: 3/10, Age group: B (4-5) Smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945be132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 43.1 mb\n",
    "# 1 Grammar: 5/10, Creativity: 6/10, Consistency: 5/10, Age group: C (6-7) Very Smaller\n",
    "# 2 Grammar: 4/10, Creativity: 6/10, Consistency: 3/10, Age group: B (4-5)\n",
    "# 3 Grammar: 5/10, Creativity: 5/10, Consistency: 4/10, Age group: C (6-7) Medium Smaller\n",
    "# 4 Grammar: 5/10, Creativity: 6/10, Consistency: 5/10, Age group: C (6-7) Smaller\n",
    "# 5 Grammar: 5/10, Creativity: 6/10, Consistency: 4/10, Age group: C (6-7) Smaller\n",
    "# 6 Grammar: 4/10, Creativity: 5/10, Consistency: 3/10, Age group: B (4-5) Medium Smaller\n",
    "# 7 Grammar: 2/10, Creativity: 4/10, Consistency: 2/10, Age group: A (3 or under) Smaller\n",
    "# 8 Grammar: 4/10, Creativity: 5/10, Consistency: 4/10, Age group: B (4-5) Very Smaller\n",
    "# 9 Grammar: 7/10, Creativity: 6/10, Consistency: 6/10, Age group: C (6-7) Smaller\n",
    "# 10 Grammar: 7/10, Creativity: 6/10, Consistency: 6/10, Age group: C (6-7) Smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b947248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 42.1 mb (Second try fixed vocab)\n",
    "# 1 Grammar: 7/10, Creativity: 6/10, Consistency: 6/10, Age group: C (6-7) Medium Smaller\n",
    "# 2 Grammar: 7/10, Creativity: 6/10, Consistency: 6/10, Age group: C (6-7) Medium Smaller\n",
    "# 3 Grammar: 6/10, Creativity: 6/10, Consistency: 5/10, Age group: C (6-7) Second try Smaller\n",
    "# 4 Grammar: 7/10, Creativity: 6/10, Consistency: 6/10, Age group: C (6-7) Medium Smaller\n",
    "# 5 Grammar: 6/10, Creativity: 6/10, Consistency: 5/10, Age group: C (6-7)\n",
    "# 6 Grammar: 7/10, Creativity: 7/10, Consistency: 6/10, Age group: C (6-7) Smaller\n",
    "# 7 Grammar: 7/10, Creativity: 7/10, Consistency: 6/10, Age group: C (6-7) Medium Smaller\n",
    "\n",
    "# 8 Grammar: 3/10, Creativity: 5/10, Consistency: 3/10, Age group: B (4-5) Smaller - Another GPTChat, another answer...\n",
    "# 8 Grammar: 6/10, Creativity: 6/10, Consistency: 5/10, Age group: C (6-7) Another GPTChat, another answer...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327d774f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
