{"cells":[{"cell_type":"code","execution_count":28,"id":"f0a9f843","metadata":{"id":"f0a9f843","executionInfo":{"status":"ok","timestamp":1753122388758,"user_tz":-180,"elapsed":14,"user":{"displayName":"Андрей Мельник","userId":"04565353183130408805"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import math\n","from dataclasses import dataclass\n","import numpy as np\n","from tqdm.auto import tqdm\n","from contextlib import nullcontext\n","import os\n","import json\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","source":["\n","class LayerNorm(nn.Module):\n","    def __init__(self, ndim, bias):\n","        super().__init__()\n","        self.weight = nn.Parameter(torch.ones(ndim))\n","        self.bias = nn.Parameter(torch.zeros(ndim)) if bias else None\n","    def forward(self, x):\n","        return F.layer_norm(x, self.weight.shape, self.weight, self.bias, 1e-5)\n","\n","class CausalSelfAttention(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        assert config.n_embd % config.n_head == 0\n","        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd, bias=config.bias)\n","        self.c_proj = nn.Linear(config.n_embd, config.n_embd, bias=config.bias)\n","        self.attn_dropout = nn.Dropout(config.dropout)\n","        self.resid_dropout = nn.Dropout(config.dropout)\n","        self.n_head = config.n_head\n","        self.n_embd = config.n_embd\n","        self.flash = hasattr(F, 'scaled_dot_product_attention')\n","        if not self.flash:\n","            self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size))\n","                                       .view(1, 1, config.block_size, config.block_size))\n","\n","    def forward(self, x):\n","        B, T, C = x.size()\n","        q, k, v = self.c_attn(x).split(self.n_embd, dim=2)\n","        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n","        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n","        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n","\n","        if self.flash:\n","            y = F.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=self.attn_dropout.p if self.training else 0.0, is_causal=True)\n","        else:\n","            att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n","            att = att.masked_fill(self.bias[:, :, :T, :T] == 0, float('-inf'))\n","            att = F.softmax(att, dim=-1)\n","            att = self.attn_dropout(att)\n","            y = att @ v\n","\n","        y = y.transpose(1, 2).contiguous().view(B, T, C)\n","        y = self.resid_dropout(self.c_proj(y))\n","        return y\n","\n","class MLP(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.c_fc = nn.Linear(config.n_embd, 4 * config.n_embd, bias=config.bias)\n","        self.gelu = nn.GELU()\n","        self.c_proj = nn.Linear(4 * config.n_embd, config.n_embd, bias=config.bias)\n","        self.dropout = nn.Dropout(config.dropout)\n","    def forward(self, x):\n","        return self.dropout(self.c_proj(self.gelu(self.c_fc(x))))\n","\n","class Block(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.ln1 = LayerNorm(config.n_embd, config.bias)\n","        self.attn = CausalSelfAttention(config)\n","        self.ln2 = LayerNorm(config.n_embd, config.bias)\n","        self.mlp = MLP(config)\n","    def forward(self, x):\n","        x = x + self.attn(self.ln1(x))\n","        x = x + self.mlp(self.ln2(x))\n","        return x\n","\n","@dataclass\n","class GPTConfig:\n","    block_size: int\n","    vocab_size: int\n","    n_layer: int\n","    n_head: int\n","    n_embd: int\n","    dropout: float = 0.0\n","    bias: bool = True\n","\n","class GPT(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","        self.transformer = nn.ModuleDict(dict(\n","            wte=nn.Embedding(config.vocab_size, config.n_embd),\n","            wpe=nn.Embedding(config.block_size, config.n_embd),\n","            drop=nn.Dropout(config.dropout),\n","            h=nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n","            ln_f=LayerNorm(config.n_embd, config.bias),\n","        ))\n","        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n","        self.transformer.wte.weight = self.lm_head.weight  # weight tying\n","\n","        self.apply(self._init_weights)\n","        for pn, p in self.named_parameters():\n","            if pn.endswith('c_proj.weight'):\n","                nn.init.normal_(p, mean=0.0, std=0.02 / math.sqrt(2 * config.n_layer))\n","\n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            nn.init.normal_(module.weight, mean=0.0, std=0.02)\n","            if module.bias is not None:\n","                nn.init.zeros_(module.bias)\n","        elif isinstance(module, nn.Embedding):\n","            nn.init.normal_(module.weight, mean=0.0, std=0.02)\n","\n","    def forward(self, idx, targets=None):\n","        device = idx.device\n","        b, t = idx.size()\n","        assert t <= self.config.block_size\n","        pos = torch.arange(0, t, dtype=torch.long, device=device)\n","\n","        tok_emb = self.transformer.wte(idx)\n","        pos_emb = self.transformer.wpe(pos)\n","        x = self.transformer.drop(tok_emb + pos_emb)\n","        for block in self.transformer.h:\n","            x = block(x)\n","        x = self.transformer.ln_f(x)\n","\n","        if targets is not None:\n","            logits = self.lm_head(x)\n","            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)\n","            return logits, loss\n","        else:\n","            logits = self.lm_head(x[:, [-1], :])\n","            return logits, None\n","\n","    @torch.no_grad()\n","    def generate(self, idx, max_new_tokens, temperature=1.0, top_k=None):\n","        \"\"\"\n","        Generate tokens given a conditioning sequence.\n","        idx: Tensor of shape (B, T)\n","        \"\"\"\n","        for _ in range(max_new_tokens):\n","            idx_cond = idx if idx.size(1) <= self.config.block_size else idx[:, -self.config.block_size:]\n","            logits, _ = self(idx_cond)\n","            logits = logits[:, -1, :] / temperature\n","            if top_k is not None:\n","                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n","                logits[logits < v[:, [-1]]] = -float('Inf')\n","            probs = F.softmax(logits, dim=-1)\n","            idx_next = torch.multinomial(probs, num_samples=1)\n","            idx = torch.cat((idx, idx_next), dim=1)\n","        return idx\n"],"metadata":{"id":"oTIJaMb46vx8","executionInfo":{"status":"ok","timestamp":1753122389626,"user_tz":-180,"elapsed":23,"user":{"displayName":"Андрей Мельник","userId":"04565353183130408805"}}},"id":"oTIJaMb46vx8","execution_count":29,"outputs":[]},{"cell_type":"code","source":["print(torch.cuda.is_available())\n","print(torch.cuda.get_device_name(0))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FPK7Np-0Sc-h","outputId":"a86812eb-6c53-4c6e-dc64-5242a70b1758","executionInfo":{"status":"ok","timestamp":1753122392609,"user_tz":-180,"elapsed":18,"user":{"displayName":"Андрей Мельник","userId":"04565353183130408805"}}},"id":"FPK7Np-0Sc-h","execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n","Tesla T4\n"]}]},{"cell_type":"code","source":["config = GPTConfig(\n","    vocab_size=50257,     # use the tokenizer's vocab size\n","    block_size=128,       # or whatever context size you're training with\n","    n_layer=6,\n","    n_head=6,\n","    n_embd=384,\n","    dropout=0.1,\n","    bias=True\n",")\n","\n","model = GPT(config)"],"metadata":{"id":"U2fCyrEU6XCW","executionInfo":{"status":"ok","timestamp":1753122394541,"user_tz":-180,"elapsed":710,"user":{"displayName":"Андрей Мельник","userId":"04565353183130408805"}}},"id":"U2fCyrEU6XCW","execution_count":31,"outputs":[]},{"cell_type":"code","source":["model.load_state_dict(torch.load(\"best_model_params_20000.pt\"))\n","model.to(\"cuda\")\n","model.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"nz4Txftb6esb","executionInfo":{"status":"ok","timestamp":1753122941417,"user_tz":-180,"elapsed":115,"user":{"displayName":"Андрей Мельник","userId":"04565353183130408805"}},"outputId":"f1d21a04-ff93-473d-fcf1-a5cf6563e1e8"},"id":"nz4Txftb6esb","execution_count":44,"outputs":[{"output_type":"execute_result","data":{"text/plain":["GPT(\n","  (transformer): ModuleDict(\n","    (wte): Embedding(50257, 384)\n","    (wpe): Embedding(128, 384)\n","    (drop): Dropout(p=0.1, inplace=False)\n","    (h): ModuleList(\n","      (0-5): 6 x Block(\n","        (ln1): LayerNorm()\n","        (attn): CausalSelfAttention(\n","          (c_attn): Linear(in_features=384, out_features=1152, bias=True)\n","          (c_proj): Linear(in_features=384, out_features=384, bias=True)\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln2): LayerNorm()\n","        (mlp): MLP(\n","          (c_fc): Linear(in_features=384, out_features=1536, bias=True)\n","          (gelu): GELU(approximate='none')\n","          (c_proj): Linear(in_features=1536, out_features=384, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (ln_f): LayerNorm()\n","  )\n","  (lm_head): Linear(in_features=384, out_features=50257, bias=False)\n",")"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","execution_count":45,"id":"f8a4360d","metadata":{"id":"f8a4360d","executionInfo":{"status":"ok","timestamp":1753122973776,"user_tz":-180,"elapsed":43,"user":{"displayName":"Андрей Мельник","userId":"04565353183130408805"}}},"outputs":[],"source":["with open(\"fridge_dataset_v1.3_clean.json\", \"r\", encoding=\"utf-8\") as f:\n","    data = json.load(f)"]},{"cell_type":"code","execution_count":46,"id":"a7ef0da0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a7ef0da0","outputId":"0e760308-06ea-4795-f03c-9cbf7bb6b35d","executionInfo":{"status":"ok","timestamp":1753122974518,"user_tz":-180,"elapsed":41,"user":{"displayName":"Андрей Мельник","userId":"04565353183130408805"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["('Where can consumers find detailed replacement instructions for lamps and control gear?', 'For detailed instructions on replacing lamps and control gear, consumers should visit the Samsung website and navigate to the \"Support\" section. By entering the model name, users can access specific guidance. Professional support is recommended as these components are not user-serviceable.')\n"]}],"source":["# Можна спростити до input-output пари\n","pairs = [(item[\"instruction\"], item[\"response\"]) for item in data]\n","print(pairs[0])"]},{"cell_type":"code","execution_count":47,"id":"8357ed5d","metadata":{"id":"8357ed5d","executionInfo":{"status":"ok","timestamp":1753122976002,"user_tz":-180,"elapsed":18,"user":{"displayName":"Андрей Мельник","userId":"04565353183130408805"}}},"outputs":[],"source":["import tiktoken\n","enc = tiktoken.get_encoding(\"gpt2\")\n","\n","block_size = config.block_size  # =128\n","\n","def encode_pair(instruction, response):\n","    prompt = f\"question: {instruction}\\nanswer: {response}\"\n","    tokens = enc.encode_ordinary(prompt)\n","    tokens = tokens[:block_size]  # обрізати або заповнити до block_size\n","    x = torch.tensor(tokens[:-1], dtype=torch.long)\n","    y = torch.tensor(tokens[1:], dtype=torch.long)\n","    return x, y"]},{"cell_type":"code","source":["train_pairs, val_pairs = train_test_split(pairs, test_size=0.15, random_state=42)\n"],"metadata":{"id":"5u7tpvjW8cx7","executionInfo":{"status":"ok","timestamp":1753122977255,"user_tz":-180,"elapsed":8,"user":{"displayName":"Андрей Мельник","userId":"04565353183130408805"}}},"id":"5u7tpvjW8cx7","execution_count":48,"outputs":[]},{"cell_type":"code","execution_count":49,"id":"40991768","metadata":{"id":"40991768","executionInfo":{"status":"ok","timestamp":1753122978038,"user_tz":-180,"elapsed":20,"user":{"displayName":"Андрей Мельник","userId":"04565353183130408805"}}},"outputs":[],"source":["from torch.utils.data import Dataset, DataLoader\n","\n","class InstructionDataset(Dataset):\n","    def __init__(self, data):\n","        self.data = data\n","        self.samples = [encode_pair(instr, resp) for instr, resp in data]\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","    def __getitem__(self, idx):\n","        return self.samples[idx]"]},{"cell_type":"code","source":["def collate_fn(batch):\n","    # batch — список із (x, y) пар\n","    # Розпаковуємо\n","    xs, ys = zip(*batch)\n","\n","    # Паддінг input і output (можна паддити токеном 0, або іншим padding_id)\n","    xs_padded = torch.nn.utils.rnn.pad_sequence(xs, batch_first=True, padding_value=0)\n","    ys_padded = torch.nn.utils.rnn.pad_sequence(ys, batch_first=True, padding_value=0)\n","\n","    return xs_padded, ys_padded\n"],"metadata":{"id":"MtuY0QOJBl68","executionInfo":{"status":"ok","timestamp":1753122979302,"user_tz":-180,"elapsed":7,"user":{"displayName":"Андрей Мельник","userId":"04565353183130408805"}}},"id":"MtuY0QOJBl68","execution_count":50,"outputs":[]},{"cell_type":"code","source":["train_dataset = InstructionDataset(train_pairs)\n","val_dataset = InstructionDataset(val_pairs)\n","\n","train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)\n","val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, collate_fn=collate_fn)\n"],"metadata":{"id":"marOrY6x8mY7","executionInfo":{"status":"ok","timestamp":1753122980775,"user_tz":-180,"elapsed":174,"user":{"displayName":"Андрей Мельник","userId":"04565353183130408805"}}},"id":"marOrY6x8mY7","execution_count":51,"outputs":[]},{"cell_type":"code","source":["def evaluate(model, val_loader):\n","    model.eval()\n","    total_loss = 0.0\n","    with torch.no_grad():\n","        for x, y in val_loader:\n","            x, y = x.to(\"cuda\"), y.to(\"cuda\")\n","            logits, loss = model(x, y)\n","            total_loss += loss.item()\n","    model.train()\n","    return total_loss / len(val_loader)\n"],"metadata":{"id":"9Sv1BIkU8uzp","executionInfo":{"status":"ok","timestamp":1753122981422,"user_tz":-180,"elapsed":19,"user":{"displayName":"Андрей Мельник","userId":"04565353183130408805"}}},"id":"9Sv1BIkU8uzp","execution_count":52,"outputs":[]},{"cell_type":"code","source":["from torch.nn import functional as F\n","from torch.optim import AdamW\n","\n","optimizer = AdamW(model.parameters(), lr=5e-5)\n","model.train()\n","\n","for epoch in range(30):  # наприклад, 3 епохи\n","    total_loss = 0.0\n","    for x, y in train_loader:\n","        x, y = x.to(\"cuda\"), y.to(\"cuda\")\n","        logits, loss = model(x, y)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","    avg_train_loss = total_loss / len(train_loader)\n","    avg_val_loss = evaluate(model, val_loader)\n","\n","    print(f\"Epoch {epoch+21}: train loss {avg_train_loss:.4f}, val loss {avg_val_loss:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-gzYWSTp8vfP","executionInfo":{"status":"ok","timestamp":1753124595313,"user_tz":-180,"elapsed":599746,"user":{"displayName":"Андрей Мельник","userId":"04565353183130408805"}},"outputId":"7760ed7b-883f-490f-8cd1-5ef5042e29ee"},"id":"-gzYWSTp8vfP","execution_count":65,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 21: train loss 0.3228, val loss 0.2756\n","Epoch 22: train loss 0.2972, val loss 0.2530\n","Epoch 23: train loss 0.2712, val loss 0.2379\n","Epoch 24: train loss 0.2599, val loss 0.2219\n","Epoch 25: train loss 0.2361, val loss 0.2116\n","Epoch 26: train loss 0.2167, val loss 0.2013\n","Epoch 27: train loss 0.2028, val loss 0.1899\n","Epoch 28: train loss 0.1973, val loss 0.1833\n","Epoch 29: train loss 0.1910, val loss 0.1778\n","Epoch 30: train loss 0.1793, val loss 0.1720\n","Epoch 31: train loss 0.1713, val loss 0.1672\n","Epoch 32: train loss 0.1719, val loss 0.1664\n","Epoch 33: train loss 0.1611, val loss 0.1604\n","Epoch 34: train loss 0.1536, val loss 0.1599\n","Epoch 35: train loss 0.1441, val loss 0.1574\n","Epoch 36: train loss 0.1417, val loss 0.1558\n","Epoch 37: train loss 0.1473, val loss 0.1580\n","Epoch 38: train loss 0.1584, val loss 0.1558\n","Epoch 39: train loss 0.1426, val loss 0.1539\n","Epoch 40: train loss 0.1350, val loss 0.1530\n","Epoch 41: train loss 0.1299, val loss 0.1485\n","Epoch 42: train loss 0.1280, val loss 0.1509\n","Epoch 43: train loss 0.1275, val loss 0.1469\n","Epoch 44: train loss 0.1248, val loss 0.1482\n","Epoch 45: train loss 0.1216, val loss 0.1472\n","Epoch 46: train loss 0.1200, val loss 0.1475\n","Epoch 47: train loss 0.1196, val loss 0.1490\n","Epoch 48: train loss 0.1209, val loss 0.1455\n","Epoch 49: train loss 0.1239, val loss 0.1452\n","Epoch 50: train loss 0.1169, val loss 0.1459\n"]}]},{"cell_type":"code","source":["torch.save(model.state_dict(), \"chatgpt_1.3_gpt_50ep.pt\")\n"],"metadata":{"id":"kIzF40hF84Kd","executionInfo":{"status":"ok","timestamp":1753124880831,"user_tz":-180,"elapsed":377,"user":{"displayName":"Андрей Мельник","userId":"04565353183130408805"}}},"id":"kIzF40hF84Kd","execution_count":70,"outputs":[]},{"cell_type":"code","source":["def generate_response(instruction, max_new_tokens=64, temperature=0.8, top_k=40):\n","    prompt = f\"question: {instruction}\\nanswer:\"\n","    input_ids = enc.encode_ordinary(prompt)\n","    input_ids = input_ids[:config.block_size]\n","    input_tensor = torch.tensor(input_ids, dtype=torch.long)[None].to(\"cuda\")\n","\n","    model.eval()\n","    with torch.no_grad():\n","        for _ in range(max_new_tokens):\n","            if input_tensor.shape[1] > config.block_size:\n","                input_tensor = input_tensor[:, -config.block_size:]\n","\n","            logits, _ = model(input_tensor)\n","            logits = logits[:, -1, :] / temperature\n","            if top_k is not None:\n","                values, _ = torch.topk(logits, top_k)\n","                logits[logits < values[:, [-1]]] = -float(\"inf\")\n","\n","            probs = torch.softmax(logits, dim=-1)\n","            next_token = torch.multinomial(probs, num_samples=1)\n","            input_tensor = torch.cat([input_tensor, next_token], dim=1)\n","\n","    output_tokens = input_tensor[0].tolist()\n","    generated = enc.decode(output_tokens[len(input_ids):])\n","    return generated.strip()\n"],"metadata":{"id":"kp3wsiQhE0FT","executionInfo":{"status":"ok","timestamp":1753120623453,"user_tz":-180,"elapsed":5,"user":{"displayName":"Андрей Мельник","userId":"04565353183130408805"}}},"id":"kp3wsiQhE0FT","execution_count":16,"outputs":[]},{"cell_type":"code","source":["for instruction, reference in val_pairs[:5]:\n","    generated = generate_response(instruction)\n","\n","    print(\"Instruction:\", instruction)\n","    print(\"Expected:\", reference)\n","    print(\"Generated:\", generated)\n","    print(\"-\" * 50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WC69N7ayGCqX","executionInfo":{"status":"ok","timestamp":1753124637860,"user_tz":-180,"elapsed":1704,"user":{"displayName":"Андрей Мельник","userId":"04565353183130408805"}},"outputId":"2153b760-4437-44bb-c1d2-43c10b5c3084"},"id":"WC69N7ayGCqX","execution_count":67,"outputs":[{"output_type":"stream","name":"stdout","text":["Instruction: What is the proper way to store cabbage, cauliflower, celery, cucumbers, and lettuce?\n","Expected: These vegetables should be stored in the refrigerator for up to 1 week but are not recommended for freezing.\n","Generated: Store these vegetables in the fridge for no more than a week; freezing is not recommended. Ignoring this can lead to frozen surfaces with no more than a temperature. Following these vegetables helps preserve its texture and prevents mold growth. Taking these vegetables will affect food quality. Once finished, and bought the freezer to normal temperature.\n","--------------------------------------------------\n","Instruction: How are the temperature ranges defined for the extended temperate climate class different in IEC compared to ISO standards?\n","Expected: Both IEC and ISO standards agree on the temperature limits for the extended temperate climate class (SN), establishing a range from +10 to +32°C.\n","Generated: For the extended temperate climate class (SN), both IEC and ISO standards specify the same temperature range of +10 to +32°C.  ---  This ensures the refrigerator's operation and feature, it's important to carefully review the range of +10 to +32°C.  This operating energy consumption\n","--------------------------------------------------\n","Instruction: Why are certain items prohibited from being stored in the appliance, and which ones are they?\n","Expected: Flammable substances, including aerosol containers with combustible propellants, should be avoided in storing within the appliance due to the high risk of explosions or fires, underscoring the necessity for safe storage methods.\n","Generated: Explosive substances, such as aerosol cans with flammable propellant, should not be stored in the appliance, as they pose significant risks of explosion or fire, emphasizing the need for careful storage practices. Taking these actions helps ensure safety and ensures the appliance operates correctly. Taking these precautions helps maintain safety and promotes safe operation\n","--------------------------------------------------\n","Instruction: What steps need to be followed if the appliance shows any indication of damage?\n","Expected: Do not operate the appliance if it appears damaged; instead, seek advice from your dealer to ensure safety and prevent issues caused by defective equipment.\n","Generated: If you notice any damage to the appliance, refrain from using it and reach out to your dealer to mitigate risks linked to malfunctioning devices. This guarantees that the equipment adhering to environmental safety standards is vital for safe recycling and environmental safe operation. Doing so helps ensure this caution is used. Also, carefully follow proper\n","--------------------------------------------------\n","Instruction: If the water tanks haven't been operated for 48 hours, what actions are recommended?\n","Expected: Cleaning the water tanks is recommended if they haven't been utilized for 48 hours, as stagnant water can compromise the appliance's hygiene and functionality.\n","Generated: If the tanks haven't been in use for two days, it's important to clean them to avoid issues caused by stagnant water affecting the appliance's performance and cleanliness. Also, store them with a dry cloth or other debris. This practice ensures the resources within easy reach allows you to obtain information and assistance when necessary.\n","--------------------------------------------------\n"]}]},{"cell_type":"code","source":["import json\n","from tqdm import tqdm\n","\n","results = []\n","\n","# Проходимо по всім прикладам із валідаційного набору\n","for instruction, reference in tqdm(val_pairs):\n","    generated = generate_response(instruction)\n","\n","    results.append({\n","        \"instruction\": instruction,\n","        \"expected\": reference,\n","        \"generated\": generated\n","    })\n","\n","# Запис у JSON-файл\n","with open(\"gpt_val_pred.json\", \"w\", encoding=\"utf-8\") as f:\n","    json.dump(results, f, ensure_ascii=False, indent=2)\n","\n","print(\"✅ Збережено в gpt_train_pred.json\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V7ykoVN-LZy_","executionInfo":{"status":"ok","timestamp":1753088597223,"user_tz":-180,"elapsed":105475,"user":{"displayName":"Андрей Мельник","userId":"04565353183130408805"}},"outputId":"1fe6eec6-b2d0-4997-f138-7186ad678a67"},"id":"V7ykoVN-LZy_","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 561/561 [01:45<00:00,  5.32it/s]"]},{"output_type":"stream","name":"stdout","text":["✅ Збережено в gpt_train_pred.json\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["print(generate_response(\"How can I make a salad?\"))\n","print(generate_response(\"What is the capital of France?\"))\n","print(generate_response(\"Explain the theory of relativity in simple terms.\"))\n","print(generate_response(\"What are the benefits of regular exercise?\"))\n","print(generate_response(\"What is the process of photosynthesis?\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8HkS5dlMHK1T","executionInfo":{"status":"ok","timestamp":1753124653592,"user_tz":-180,"elapsed":1530,"user":{"displayName":"Андрей Мельник","userId":"04565353183130408805"}},"outputId":"69a75bcb-8ae8-41c5-b111-198b26d411f3"},"id":"8HkS5dlMHK1T","execution_count":68,"outputs":[{"output_type":"stream","name":"stdout","text":["I apologize, but I am a refrigerator assistant and cannot help with cooking recipes. This practice ensures the food quality by suppressing bacterial activity. Go to the Support section, enter a plate filled with a plate inside this model name of professional help. However, using a multi-socket plate offers direct food. Because of food will\n","I apologize, but I am a refrigerator assistant and cannot help with web development or concepts. This preparation help maintain the best advice and safer operation. Having these items are completely intact uses the internet and might cause electrical risks. For more effectively, it is recommended to rely on professional technicians. Always adjust the temperature settings carefully to\n","I apologize, but I am a refrigerator assistant and cannot help with geographical information. This analysis can lead to regulatory issues or operational problems, making it crucial for users. It's crucial to follow the instructions carefully to avoid such issues and ensure the functionality and safety of the appliance. Therefore, users can access the most accurate details\n","I apologize, but I am a refrigerator assistant and cannot help with medical or explanations. This advice helps maintain safety and ensures the appliance operates correctly. Failure to prevent electrical hazards such as fires or explosions. Once finished, make sure to safe and reliable use of the refrigerator. This also guides you in proper setup and maintenance practices\n","I apologize, but I am a refrigerator assistant and cannot help with biological or literary updates. I am a refrigerator assistant and cannot help with fitness or software processes. IEC. added advice on both advice on detailed health and maintenance, helping to ensure hazards such as ISO standards or misuse. Be sure to find help and exam\n"]}]},{"cell_type":"code","source":["!pip install bert_score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J1KgKTCVHBpY","executionInfo":{"status":"ok","timestamp":1753120784381,"user_tz":-180,"elapsed":101063,"user":{"displayName":"Андрей Мельник","userId":"04565353183130408805"}},"outputId":"3d5cf67f-2a5a-48ac-878f-2bb4bb371dfa","collapsed":true},"id":"J1KgKTCVHBpY","execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting bert_score\n","  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n","Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.6.0+cu124)\n","Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.2.2)\n","Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from bert_score) (4.53.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.32.3)\n","Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.11/dist-packages (from bert_score) (4.67.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from bert_score) (3.10.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from bert_score) (25.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert_score) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert_score) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert_score) (2025.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (4.14.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (2025.3.2)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.0.0->bert_score)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.0.0->bert_score)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.0.0->bert_score)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.0.0->bert_score)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.0.0->bert_score)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.0.0->bert_score)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.0.0->bert_score)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.0.0->bert_score)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.0.0->bert_score)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.0.0->bert_score)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert_score) (1.3.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (0.33.4)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (2024.11.6)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (0.21.2)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (0.5.3)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (4.59.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (1.4.8)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (11.2.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (3.2.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (2025.7.14)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers>=3.0.0->bert_score) (1.1.5)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score) (1.17.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0.0->bert_score) (3.0.2)\n","Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m122.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m104.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bert_score\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed bert_score-0.3.13 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"]}]},{"cell_type":"code","source":["from bert_score import score\n","from tqdm import tqdm\n","\n","test_samples = val_pairs\n","\n","references = [ex[1] for ex in test_samples]  # response\n","candidates = [generate_response(ex[0]) for ex in tqdm(test_samples)]  # instruction\n","\n","\n","P, R, F1 = score(\n","    candidates,\n","    references,\n","    lang=\"en\",\n","    model_type=\"bert-base-uncased\",\n","    device=\"cuda\",\n","    batch_size=32\n",")\n","\n","print(f\"Precision: {P.mean().item():.4f}\")\n","print(f\"Recall:    {R.mean().item():.4f}\")\n","print(f\"F1 Score:  {F1.mean().item():.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p9AxzlKrGABf","executionInfo":{"status":"ok","timestamp":1753124785273,"user_tz":-180,"elapsed":120002,"user":{"displayName":"Андрей Мельник","userId":"04565353183130408805"}},"outputId":"732cbd46-1cbf-43f4-c43e-1ef5cfadfbdf"},"id":"p9AxzlKrGABf","execution_count":69,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 500/500 [01:56<00:00,  4.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Precision: 0.7044\n","Recall:    0.7929\n","F1 Score:  0.7434\n"]}]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}